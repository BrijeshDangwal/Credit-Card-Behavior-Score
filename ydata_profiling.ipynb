{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'Dataset\\validation_data_to_be_shared 3\\validation_data_to_be_shared.csv', delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')\n",
    "new = pd.read_csv(r'feature_importance.csv', delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1214, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a3f26b05f421ba6b4632924b0ec78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n",
      "c:\\Users\\dangw\\anaconda3\\envs\\convolve\\lib\\site-packages\\ydata_profiling\\model\\pandas\\duplicates_pandas.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[duplicated_rows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066905d1ff81406b99c2dd6162b6ec18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a04478a927741269b7c089b6ddc4eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abf212f7ea34689beeb764e6ef661bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(data, title=\"Dataset Profiling Report\", explorative=True)\n",
    "\n",
    "# Save the report to an HTML file\n",
    "profile.to_file(\"feature.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations = correlation_matrix[\"bad_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations_sorted = bad_flag_correlations.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_flag                     1.000000\n",
      "transaction_attribute_619    0.055718\n",
      "transaction_attribute_189    0.051315\n",
      "transaction_attribute_515    0.050001\n",
      "transaction_attribute_513    0.048391\n",
      "                               ...   \n",
      "transaction_attribute_51     0.000061\n",
      "transaction_attribute_481    0.000059\n",
      "transaction_attribute_416    0.000041\n",
      "transaction_attribute_587    0.000032\n",
      "transaction_attribute_253    0.000018\n",
      "Name: bad_flag, Length: 666, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(bad_flag_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_flag                     1.000000\n",
       "transaction_attribute_619    0.055718\n",
       "transaction_attribute_189    0.051315\n",
       "transaction_attribute_515    0.050001\n",
       "transaction_attribute_513    0.048391\n",
       "transaction_attribute_98     0.046199\n",
       "transaction_attribute_332    0.045276\n",
       "transaction_attribute_333    0.041800\n",
       "transaction_attribute_658    0.037483\n",
       "transaction_attribute_99     0.036050\n",
       "transaction_attribute_441    0.035938\n",
       "transaction_attribute_516    0.035428\n",
       "transaction_attribute_257    0.034873\n",
       "transaction_attribute_388    0.034821\n",
       "transaction_attribute_643    0.034339\n",
       "transaction_attribute_512    0.032848\n",
       "transaction_attribute_437    0.032504\n",
       "transaction_attribute_331    0.031855\n",
       "transaction_attribute_286    0.030569\n",
       "transaction_attribute_438    0.030284\n",
       "transaction_attribute_514    0.029882\n",
       "transaction_attribute_633    0.028828\n",
       "transaction_attribute_23     0.028528\n",
       "transaction_attribute_213    0.027090\n",
       "transaction_attribute_287    0.026158\n",
       "transaction_attribute_391    0.026108\n",
       "transaction_attribute_52     0.025897\n",
       "transaction_attribute_228    0.025576\n",
       "transaction_attribute_203    0.024531\n",
       "transaction_attribute_288    0.024475\n",
       "Name: bad_flag, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_flag_correlations_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = pd.read_csv(r'bureau_data.csv', delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')\n",
    "data_be = pd.read_csv(r'bureau_enquiry_data.csv', delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = data_b.fillna(0)\n",
    "data_be = data_be.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_b = data_b.corr()\n",
    "correlation_matrix_be = data_be.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations_b = correlation_matrix_b[\"bad_flag\"]\n",
    "bad_flag_correlations_be = correlation_matrix_be[\"bad_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations_sorted_b = bad_flag_correlations_b.abs().sort_values(ascending=False)\n",
    "bad_flag_correlations_sorted_be = bad_flag_correlations_be.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_flag      1.000000\n",
       "bureau_14     0.061340\n",
       "bureau_24     0.060846\n",
       "bureau_105    0.059938\n",
       "bureau_21     0.059640\n",
       "                ...   \n",
       "bureau_437    0.028455\n",
       "bureau_355    0.028224\n",
       "bureau_113    0.027870\n",
       "bureau_448    0.027754\n",
       "bureau_103    0.027140\n",
       "Name: bad_flag, Length: 80, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_flag_correlations_sorted_b.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad_flag             1.000000\n",
       "bureau_enquiry_13    0.074001\n",
       "bureau_enquiry_11    0.073359\n",
       "bureau_enquiry_23    0.072295\n",
       "bureau_enquiry_21    0.072268\n",
       "bureau_enquiry_31    0.070906\n",
       "bureau_enquiry_33    0.070610\n",
       "bureau_enquiry_41    0.070031\n",
       "bureau_enquiry_43    0.070027\n",
       "bureau_enquiry_3     0.068871\n",
       "bureau_enquiry_1     0.068171\n",
       "bureau_enquiry_35    0.065466\n",
       "bureau_enquiry_25    0.064953\n",
       "bureau_enquiry_45    0.064224\n",
       "bureau_enquiry_15    0.063270\n",
       "bureau_enquiry_50    0.050408\n",
       "bureau_enquiry_5     0.050328\n",
       "bureau_enquiry_10    0.047967\n",
       "bureau_enquiry_40    0.047815\n",
       "bureau_enquiry_20    0.047532\n",
       "bureau_enquiry_30    0.047378\n",
       "bureau_enquiry_48    0.035364\n",
       "bureau_enquiry_38    0.029683\n",
       "bureau_enquiry_28    0.019402\n",
       "bureau_enquiry_32    0.018134\n",
       "bureau_enquiry_42    0.017998\n",
       "bureau_enquiry_22    0.014824\n",
       "bureau_enquiry_18    0.014532\n",
       "bureau_enquiry_34    0.013512\n",
       "bureau_enquiry_44    0.011804\n",
       "Name: bad_flag, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_flag_correlations_sorted_be.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset/Dev_data_to_be_shared 3/Dev_data_to_be_shared.csv', delimiter=',',escapechar='\\\\',header=0,on_bad_lines='skip', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations = correlation_matrix[\"bad_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_flag_correlations_sorted = bad_flag_correlations.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_flag             1.000000\n",
      "onus_attribute_2     0.108491\n",
      "onus_attribute_17    0.103156\n",
      "onus_attribute_23    0.100748\n",
      "onus_attribute_20    0.100672\n",
      "                       ...   \n",
      "bureau_enquiry_7          NaN\n",
      "bureau_enquiry_17         NaN\n",
      "bureau_enquiry_27         NaN\n",
      "bureau_enquiry_37         NaN\n",
      "bureau_enquiry_47         NaN\n",
      "Name: bad_flag, Length: 1216, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(bad_flag_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bad_flag_correlations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Attribute     Value\n",
      "0              bad_flag  1.000000\n",
      "1      onus_attribute_2  0.108491\n",
      "2     onus_attribute_17  0.103156\n",
      "3     onus_attribute_23  0.100748\n",
      "4     onus_attribute_20  0.100672\n",
      "...                 ...       ...\n",
      "1211   bureau_enquiry_7       NaN\n",
      "1212  bureau_enquiry_17       NaN\n",
      "1213  bureau_enquiry_27       NaN\n",
      "1214  bureau_enquiry_37       NaN\n",
      "1215  bureau_enquiry_47       NaN\n",
      "\n",
      "[1216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert Series to DataFrame\n",
    "df = bad_flag_correlations_sorted.to_frame()\n",
    "\n",
    "# Optionally rename the column\n",
    "df.columns = ['Value']\n",
    "\n",
    "# Reset index if needed\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Attribute'}, inplace=True)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('correlation_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_correltion = df[df[\"Value\"] > 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_correltion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad_flag</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>onus_attribute_2</td>\n",
       "      <td>0.108491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onus_attribute_17</td>\n",
       "      <td>0.103156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onus_attribute_23</td>\n",
       "      <td>0.100748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onus_attribute_20</td>\n",
       "      <td>0.100672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>bureau_27</td>\n",
       "      <td>0.031136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>bureau_119</td>\n",
       "      <td>0.030790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>bureau_63</td>\n",
       "      <td>0.030667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>transaction_attribute_286</td>\n",
       "      <td>0.030569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>transaction_attribute_438</td>\n",
       "      <td>0.030284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Attribute     Value\n",
       "0                     bad_flag  1.000000\n",
       "1             onus_attribute_2  0.108491\n",
       "2            onus_attribute_17  0.103156\n",
       "3            onus_attribute_23  0.100748\n",
       "4            onus_attribute_20  0.100672\n",
       "..                         ...       ...\n",
       "137                  bureau_27  0.031136\n",
       "138                 bureau_119  0.030790\n",
       "139                  bureau_63  0.030667\n",
       "140  transaction_attribute_286  0.030569\n",
       "141  transaction_attribute_438  0.030284\n",
       "\n",
       "[142 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_correltion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convolve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
